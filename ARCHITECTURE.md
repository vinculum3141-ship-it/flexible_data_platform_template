# Architecture Documentation

## ğŸ›ï¸ System Architecture

### High-Level Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        External Users/Systems                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      FastAPI REST API          â”‚
         â”‚     (Thin Interface)           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    Application Layer           â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
         â”‚  â”‚Pipeline â”‚  â”‚  Runner  â”‚   â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      Domain Layer              â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
         â”‚  â”‚Transformersâ”‚               â”‚
         â”‚  â”‚(Pure Logic)â”‚               â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Infrastructure Layer         â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
         â”‚  â”‚Repositoriesâ”‚               â”‚
         â”‚  â”‚  Storage   â”‚               â”‚
         â”‚  â”‚  Logging   â”‚               â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                           â”‚
    â–¼                                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Storage   â”‚                         â”‚   Database   â”‚
â”‚Bronze/Silverâ”‚                         â”‚  (Metadata)  â”‚
â”‚   /Gold     â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Medallion Architecture Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Data Flow Pipeline                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Raw Data Sources
          â”‚
          â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   BRONZE LAYER       â”‚  â† Raw Data Ingestion
    â”‚  â€¢ No transformation  â”‚
    â”‚  â€¢ Original format    â”‚
    â”‚  â€¢ Full history       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ BronzeToSilverTransformer
               â”‚ â€¢ Remove duplicates
               â”‚ â€¢ Handle nulls
               â”‚ â€¢ Type conversion
               â”‚ â€¢ Quality flags
               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   SILVER LAYER       â”‚  â† Cleaned & Validated
    â”‚  â€¢ Deduplicated      â”‚
    â”‚  â€¢ Validated         â”‚
    â”‚  â€¢ Typed correctly   â”‚
    â”‚  â€¢ Quality flags     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ SilverToGoldTransformer
               â”‚ â€¢ Aggregations
               â”‚ â€¢ Business logic
               â”‚ â€¢ Derived metrics
               â”‚ â€¢ Time windows
               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   GOLD LAYER         â”‚  â† Business Ready
    â”‚  â€¢ Aggregated        â”‚
    â”‚  â€¢ Business metrics  â”‚
    â”‚  â€¢ Analytics ready   â”‚
    â”‚  â€¢ API exposed       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
       Analytics & Reports
```

## ğŸ”„ Component Interactions

### Batch Processing Flow

```
CLI/Scheduler
    â”‚
    â”œâ”€ Instantiate Components
    â”‚  â”œâ”€ Repository (based on execution_mode)
    â”‚  â”œâ”€ Transformers (based on execution_mode)
    â”‚  â””â”€ Pipeline
    â”‚
    â”œâ”€ Create BatchRunner
    â”‚  â”œâ”€ Generate batch_id
    â”‚  â”œâ”€ Start timing
    â”‚  â””â”€ Log start
    â”‚
    â””â”€ Execute Pipeline
       â”‚
       â”œâ”€ Read Bronze (Repository)
       â”‚  â””â”€ Load raw data
       â”‚
       â”œâ”€ Transform to Silver (Transformer)
       â”‚  â””â”€ Clean & validate
       â”‚
       â”œâ”€ Write Silver (Repository)
       â”‚  â”œâ”€ Save data
       â”‚  â””â”€ Save metadata
       â”‚
       â”œâ”€ Transform to Gold (Transformer)
       â”‚  â””â”€ Aggregate & compute
       â”‚
       â”œâ”€ Write Gold (Repository)
       â”‚  â”œâ”€ Save data
       â”‚  â””â”€ Save metadata
       â”‚
       â””â”€ Return Metrics
          â”œâ”€ Records processed
          â”œâ”€ Duration
          â””â”€ Success rate
```

### API Request Flow

```
HTTP Request
    â”‚
    â”œâ”€ FastAPI Router
    â”‚  â””â”€ Route matching
    â”‚
    â”œâ”€ Dependency Injection
    â”‚  â”œâ”€ get_repository()
    â”‚  â”‚  â””â”€ Returns correct repo for execution_mode
    â”‚  â””â”€ get_transformers()
    â”‚     â””â”€ Returns correct transformers
    â”‚
    â”œâ”€ Route Handler
    â”‚  â”œâ”€ /health â†’ Check repository.health_check()
    â”‚  â”œâ”€ /metrics â†’ Read gold, calculate stats
    â”‚  â””â”€ /gold â†’ Query gold layer
    â”‚
    â””â”€ Response
       â””â”€ JSON serialization
```

## ğŸ”Œ Execution Modes

### Local Mode (Pandas)
```
Settings: execution_mode=local
    â”‚
    â”œâ”€ PandasRepository
    â”‚  â”œâ”€ Reads: Parquet files
    â”‚  â”œâ”€ Writes: Parquet files
    â”‚  â””â”€ Storage: Local filesystem
    â”‚
    â””â”€ Pandas Transformers
       â”œâ”€ PandasBronzeToSilverTransformer
       â””â”€ PandasSilverToGoldTransformer
```

### Databricks Mode (Spark)
```
Settings: execution_mode=databricks
    â”‚
    â”œâ”€ SparkRepository
    â”‚  â”œâ”€ Reads: Delta Lake
    â”‚  â”œâ”€ Writes: Delta Lake
    â”‚  â””â”€ Storage: Cloud storage (S3/ADLS/GCS)
    â”‚
    â””â”€ Spark Transformers
       â”œâ”€ SparkBronzeToSilverTransformer
       â””â”€ SparkSilverToGoldTransformer
```

## ğŸ“Š Data Model

### BatchMetadata
```python
{
    "batch_id": "20260220_143022",
    "source": "cli",
    "ingestion_time": "2026-02-20T14:30:22Z",
    "record_count": 1000,
    "checksum": "abc123...",
    "layer": "silver"
}
```

### PipelineMetrics
```python
{
    "records_in": 1000,
    "records_out": 950,
    "duration_seconds": 12.5,
    "errors": 0,
    "success_rate": 95.0,
    "throughput": 80.0
}
```

## ğŸ” Security Considerations

### Authentication & Authorization
- API: Add OAuth2/JWT authentication
- Database: Use connection pooling with credentials management
- Cloud: Use IAM roles/service principals

### Data Protection
- Encryption at rest (storage layer)
- Encryption in transit (TLS/SSL)
- PII masking in transformers
- Audit logging

## ğŸ“ˆ Scalability Strategy

### Vertical Scaling
- Increase container resources (CPU/memory)
- Use larger database instances
- Optimize query performance

### Horizontal Scaling
- Multiple API instances behind load balancer
- Distributed processing with Spark
- Partitioned storage (date/entity)
- Parallel batch processing

## ğŸ” Monitoring Strategy

### Application Metrics
- Pipeline execution time
- Records processed per batch
- Error rates
- API response times

### Infrastructure Metrics
- CPU/Memory usage
- Storage utilization
- Database connections
- Network throughput

### Business Metrics
- Data quality scores
- Processing latency
- Data freshness
- Coverage metrics

## ğŸš¨ Error Handling

### Retry Strategy
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Attempt   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
   Failed? â”€â”€Noâ”€â”€> Success
       â”‚
      Yes
       â”‚
   Retry < Max? â”€â”€Noâ”€â”€> Log & Alert
       â”‚
      Yes
       â”‚
   Wait (backoff)
       â”‚
       â””â”€â”€> Retry
```

### Circuit Breaker Pattern
- Detect repeated failures
- Open circuit (stop attempts)
- Allow recovery period
- Half-open state for testing
- Close when stable

## ğŸ”„ CI/CD Pipeline

```
Code Push
    â”‚
    â”œâ”€ Linting (ruff)
    â”œâ”€ Type Checking (mypy)
    â”œâ”€ Unit Tests (pytest)
    â”œâ”€ Integration Tests
    â”œâ”€ Coverage Check
    â”‚
    â”œâ”€ Build Docker Image
    â”‚
    â”œâ”€ Security Scan
    â”‚
    â””â”€ Deploy
       â”œâ”€ Dev â†’ Automatic
       â”œâ”€ Staging â†’ Manual approval
       â””â”€ Prod â†’ Manual approval + smoke tests
```

## ğŸ“ Configuration Management

```
Environment Variables (.env)
    â”‚
    â”œâ”€ Development
    â”‚  â”œâ”€ execution_mode=local
    â”‚  â”œâ”€ log_level=DEBUG
    â”‚  â””â”€ storage_path=./data
    â”‚
    â”œâ”€ Staging
    â”‚  â”œâ”€ execution_mode=databricks
    â”‚  â”œâ”€ log_level=INFO
    â”‚  â””â”€ storage_path=/mnt/staging-data
    â”‚
    â””â”€ Production
       â”œâ”€ execution_mode=databricks
       â”œâ”€ log_level=WARNING
       â””â”€ storage_path=/mnt/prod-data
```

## ğŸ“ Extension Points

### Adding New Data Sources
1. Implement new Repository class
2. Extend BaseRepository interface
3. Update dependency injection
4. No changes to domain/application layers needed

### Adding New Transformations
1. Create new transformer classes
2. Implement transform() method
3. Keep logic pure (no I/O)
4. Inject into Pipeline

### Adding New API Endpoints
1. Define schemas in api/schemas.py
2. Add routes in api/routes.py
3. Keep handlers thin
4. Delegate to application layer

### Adding Streaming Support
1. Implement StreamingRunner fully
2. Add streaming data sources
3. Configure checkpointing
4. Add window operations in transformers
