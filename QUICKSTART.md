# Quick Start Guide

## ğŸš€ Quick Setup (5 minutes)

### 1. Setup Environment

```bash
# Create virtual environment
python3.11 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -e ".[dev]"

# Create environment file
cp .env.example .env
```

### 2. Run Your First Pipeline

```bash
# Generate sample data and run batch processing
energy-platform run-batch --generate-sample

# Output:
# âœ… Batch processing completed successfully!
# ğŸ“Š Records In: 1368
# ğŸ“Š Records Out: 60
# â±ï¸  Duration: 0.45s
# ğŸ“ˆ Success Rate: 100.0%
```

### 3. Start API Server

```bash
# Terminal 1: Start API
uvicorn app.main:app --reload

# Terminal 2: Test endpoints
curl http://localhost:8000/health
curl http://localhost:8000/metrics
curl http://localhost:8000/gold?limit=10
```

## ğŸ³ Docker Quick Start

```bash
# Start all services
docker-compose up -d

# Run batch processing
docker-compose exec app energy-platform run-batch --generate-sample

# View logs
docker-compose logs -f app

# Stop services
docker-compose down
```

## ğŸ§ª Run Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=app --cov-report=html

# Run specific test file
pytest tests/test_transformers.py -v
```

## ğŸ“‹ Common Commands

```bash
# CLI Commands
energy-platform run-batch              # Run batch pipeline
energy-platform run-batch --generate-sample  # Generate test data
energy-platform run-stream             # Run streaming (scaffold)
energy-platform health                 # Check system health

# API Server
uvicorn app.main:app --reload          # Development mode
uvicorn app.main:app --host 0.0.0.0    # Production mode

# Docker
docker-compose up -d                   # Start services
docker-compose down                    # Stop services
docker-compose logs -f app             # View logs
docker-compose exec app bash           # Shell into container

# Testing
pytest                                 # Run tests
pytest -v                              # Verbose output
pytest --cov=app                       # With coverage
black app/ tests/                      # Format code
ruff check app/                        # Lint code
mypy app/                              # Type check
```

## ğŸ¯ Directory Structure Created

```
energy_platform/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py                          # âœ… CLI entrypoint
â”‚   â”œâ”€â”€ main.py                         # âœ… FastAPI app
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                            # âœ… API Layer (thin)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ routes.py
â”‚   â”‚   â”œâ”€â”€ schemas.py
â”‚   â”‚   â””â”€â”€ dependencies.py
â”‚   â”‚
â”‚   â”œâ”€â”€ domain/                         # âœ… Domain Layer (pure logic)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”œâ”€â”€ transformers.py
â”‚   â”‚   â””â”€â”€ validation.py
â”‚   â”‚
â”‚   â”œâ”€â”€ application/                    # âœ… Application Layer (orchestration)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pipeline.py
â”‚   â”‚   â”œâ”€â”€ runner.py
â”‚   â”‚   â””â”€â”€ metrics.py
â”‚   â”‚
â”‚   â””â”€â”€ infrastructure/                 # âœ… Infrastructure Layer
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ settings.py
â”‚       â”œâ”€â”€ logging.py
â”‚       â”œâ”€â”€ monitoring.py
â”‚       â””â”€â”€ repositories/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ base.py
â”‚           â”œâ”€â”€ pandas_repository.py
â”‚           â””â”€â”€ spark_repository.py
â”‚
â”œâ”€â”€ tests/                              # âœ… Test Suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_transformers.py
â”‚   â”œâ”€â”€ test_pipeline.py
â”‚   â””â”€â”€ test_api.py
â”‚
â”œâ”€â”€ terraform/                          # âœ… Infrastructure as Code
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ variables.tf
â”‚   â”œâ”€â”€ providers.tf
â”‚   â””â”€â”€ outputs.tf
â”‚
â”œâ”€â”€ .env.example                        # âœ… Environment template
â”œâ”€â”€ .gitignore                          # âœ… Git ignore
â”œâ”€â”€ Dockerfile                          # âœ… Container image
â”œâ”€â”€ docker-compose.yml                  # âœ… Multi-container setup
â”œâ”€â”€ pyproject.toml                      # âœ… Python project config
â””â”€â”€ README.md                           # âœ… Documentation
```

## ğŸ—ï¸ Architecture Verification

âœ… **Clean Architecture Layers**
- Domain: Pure business logic, no dependencies
- Application: Use case orchestration
- Infrastructure: External concerns (storage, logging)
- API: Thin HTTP interface

âœ… **Medallion Architecture**
- Bronze â†’ Raw data ingestion
- Silver â†’ Cleaned and validated
- Gold â†’ Business-level aggregations

âœ… **Engine Abstraction**
- Pandas for local execution
- PySpark for Databricks (scaffolded)
- Configurable via `EXECUTION_MODE`

âœ… **Repository Pattern**
- Abstract base repository
- Pandas implementation (local)
- Spark implementation (Databricks)

âœ… **Metadata Tracking**
- BatchMetadata per execution
- Stored with each layer
- Enables lineage tracking

âœ… **Structured Logging**
- JSON format
- Contextual information
- No print statements

âœ… **Metrics & Monitoring**
- PipelineMetrics tracking
- Health endpoint
- Performance metrics

âœ… **Testing**
- Transformer unit tests
- Pipeline integration tests
- API endpoint tests

## ğŸ”„ Workflow Example

```bash
# 1. Generate sample data in bronze layer
energy-platform run-batch --generate-sample

# 2. View generated data
ls -la data/bronze/
ls -la data/silver/
ls -la data/gold/

# 3. Query via API
curl http://localhost:8000/metrics | jq
curl http://localhost:8000/gold?limit=5 | jq

# 4. Check health
curl http://localhost:8000/health | jq

# 5. View metadata
ls -la data/metadata/
cat data/metadata/*_metadata.json | jq
```

## ğŸ“ Adapting for Your Assignment

### Change Execution Mode to Databricks

```bash
# .env file
EXECUTION_MODE=databricks
DATABRICKS_HOST=https://your-workspace.cloud.databricks.com
DATABRICKS_TOKEN=your-token
STORAGE_PATH=/mnt/data
```

### Customize Transformations

Edit `app/domain/transformers.py`:
- Modify `PandasBronzeToSilverTransformer` for your data cleaning logic
- Modify `PandasSilverToGoldTransformer` for your aggregations
- Keep transformers pure (no I/O)

### Add New Data Sources

Edit `app/infrastructure/repositories/`:
- Extend `BaseRepository` for new storage types
- Implement read/write methods
- Update dependency injection in `app/api/dependencies.py`

### Extend API Endpoints

Edit `app/api/routes.py`:
- Add new endpoints for your use cases
- Keep logic thin (delegate to application layer)
- Add schemas in `app/api/schemas.py`

## âš¡ Performance Tips

1. **Batch Size**: Adjust `BATCH_SIZE` in settings
2. **Partitioning**: Add date/entity partitioning in repositories
3. **Caching**: Add caching layer for frequently accessed data
4. **Parallel Processing**: Use Spark for large datasets

## ğŸ”’ Production Checklist

- [ ] Configure proper authentication
- [ ] Set up secret management
- [ ] Configure SSL/TLS
- [ ] Set up monitoring dashboards
- [ ] Configure alerting
- [ ] Set up CI/CD pipeline
- [ ] Configure data retention policies
- [ ] Set up backup strategy
- [ ] Review security settings
- [ ] Load test the system

## ğŸ“ Need Help?

The project is designed to be:
- âœ… Easily adaptable
- âœ… Well-documented
- âœ… Production-ready
- âœ… Test-covered
- âœ… Cloud-agnostic

Modify any component without breaking others thanks to clean architecture!
